import os
from dotenv import load_dotenv
load_dotenv()

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.output_parsers import StrOutputParser

from utils.prompts import debator_template

google_api_key = os.getenv("google_api_key")

class DebaterAgent:
    """
    Represents an individual debater agent. Each instance has its own
    stance and uses an LLM chain to generate arguments.
    """
    def __init__(self, topic:str, stance: str, agent_name: str):
        """
        Initializes a DebaterAgent instance.

        Args:
            topic: The overarching debate topic.
            stance: The specific stance this agent will argue for.
            agent_name: The name of the agent (e.g., "Agent Alpha").
        """
        self.topic = topic
        self.stance = stance
        self.agent_name = agent_name
        self.llm = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash",
            temperature=0.7,
            google_api_key=google_api_key
        )
        self.agent_scratchpad = []
        self.parser = StrOutputParser()
        self.prompt = debator_template.partial(
            agent_scratchpad=self.agent_scratchpad  # Pass the scratchpad here
        )
    
        self.chain =self.prompt | self.llm | self.parser
        
        print(f"--- Debater Agent '{self.agent_name}' Initialized ---")
        print(f"   Topic: {self.topic}")
        print(f"   Stance: {self.stance}")
        print("---------------------------------------------")
    
    def generate_arguments(self, conversation_history: str) -> str:
        """
        Generates the next argument based on the conversation history.

        Args:
            conversation_history: A string containing the transcript of the debate so far.

        Returns:
            A string containing the agent's next argument.
        """
        print(f"Generating arguments for {self.agent_name}...")
        response_chunks = []
    
        for chunk in self.chain.stream({
            "topic": self.topic,
            "stance": self.stance,
            "conversation_history": conversation_history,
            "agent_scratchpad": self.agent_scratchpad
        }):
            response_chunks.append(chunk)
            print(chunk, end="", flush=True)  # Real-time display
        
        response = "".join(response_chunks)
        print(f"\nArguments generated by {self.agent_name}: {response}")
        return response
        
if __name__ == "__main__":
    print("testing debater agent...")
    test_topic="the role of ai in modern military",
    test_stance="AI should be used to enhance military capabilities.",
    test_agent_name="Agent Alpha"
    
    mock_history = """
    Debate Moderator: Let's begin. What is the role of AI in education?
    Agent Beta: I believe AI poses a significant threat to traditional teaching roles and may dehumanize the learning experience. We must be cautious.
    """
    agent_alpha=DebaterAgent(
        topic=test_topic,
        stance=test_stance,
        agent_name=test_agent_name
    )
    new_argument = agent_alpha.generate_arguments(mock_history)
    
    print("Debater agent test completed.")